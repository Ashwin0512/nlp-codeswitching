{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccewST_IlVW5"
      },
      "source": [
        "# Trial and error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb Cell 2\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/spacy/util.py:471\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[39mreturn\u001b[39;00m load_model_from_path(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[0;32m--> 471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
            "\u001b[0;31mOSError\u001b[0m: [E941] Can't find model 'en'. It looks like you're trying to load a model from a shortcut, which is obsolete as of spaCy v3.0. To load the model, use its full name instead:\n\nnlp = spacy.load(\"en_core_web_sm\")\n\nFor more details on the available models, see the models directory: https://spacy.io/models and if you want to create a blank model, use spacy.blank: nlp = spacy.blank(\"en\")"
          ]
        }
      ],
      "source": [
        "spacy.load('en')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "uucaP3z4FicS"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb#W1sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb#W1sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m'\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B73BkU9IG_Mp"
      },
      "outputs": [],
      "source": [
        "def break_into_independent_clauses(sentence):\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  for token in doc:\n",
        "    ancestors = [t.text for t in token.ancestors]\n",
        "    children = [t.text for t in token.children]\n",
        "    print(token.text, \"\\t\", token.i, \"\\t\",\n",
        "    token.pos_, \"\\t\", token.dep_, \"\\t\",\n",
        "    ancestors, \"\\t\", children)\n",
        "\n",
        "  def find_root_of_sentence(doc):\n",
        "    root_token = None\n",
        "    for token in doc:\n",
        "      if (token.dep_ == \"ROOT\"):\n",
        "        root_token = token\n",
        "    return root_token\n",
        "\n",
        "  root_token = find_root_of_sentence(doc)\n",
        "  print(\"\\nRoot token:\", root_token)\n",
        "\n",
        "\n",
        "  def find_other_verbs(doc, root_token):\n",
        "    other_verbs = []\n",
        "    for token in doc:\n",
        "        ancestors = list(token.ancestors)\n",
        "        if (token.pos_ == \"VERB\" and len(ancestors) >= 1 and ancestors[-1] == root_token):\n",
        "            other_verbs.append(token)\n",
        "    return other_verbs\n",
        "\n",
        "  other_verbs = find_other_verbs(doc, root_token)\n",
        "  print(\"\\nOther verbs:\", other_verbs)\n",
        "\n",
        "\n",
        "  def get_clause_token_span_for_verb(verb, doc, all_verbs):\n",
        "    first_token_index = len(doc)\n",
        "    last_token_index = 0\n",
        "    this_verb_children = list(verb.children)\n",
        "    for child in this_verb_children:\n",
        "        if (child not in all_verbs):\n",
        "            if (child.i < first_token_index):\n",
        "                first_token_index = child.i\n",
        "            if (child.i > last_token_index):\n",
        "                last_token_index = child.i\n",
        "    return(first_token_index, last_token_index)\n",
        "\n",
        "  token_spans = []\n",
        "\n",
        "  all_verbs = [root_token] + other_verbs\n",
        "  for other_verb in all_verbs:\n",
        "      (first_token_index, last_token_index) = \\\n",
        "      get_clause_token_span_for_verb(other_verb,\n",
        "                                      doc, all_verbs)\n",
        "      token_spans.append((first_token_index,\n",
        "                          last_token_index))\n",
        "      sentence_clauses = []\n",
        "\n",
        "\n",
        "  for token_span in token_spans:\n",
        "      start = token_span[0]\n",
        "      end = token_span[1]\n",
        "      if (start < end):\n",
        "          clause = doc[start:end]\n",
        "          sentence_clauses.append(clause)\n",
        "  sentence_clauses = sorted(sentence_clauses, key=lambda tup: tup[0])\n",
        "\n",
        "  clauses_text = [clause.text for clause in sentence_clauses]\n",
        "  print(clauses_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zLDyDmZvH9QS"
      },
      "outputs": [],
      "source": [
        "sentence = \"I was going for a movie today and on the way I met Sudha.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8P6HgOTVmlB"
      },
      "outputs": [],
      "source": [
        "sentence = \"The boy is playing in the garden.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBjV9ivcd3Tc"
      },
      "outputs": [],
      "source": [
        "sentence = \" He eats cheese, but he won't eat ice cream.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD8NQ2CDH6BY",
        "outputId": "a2e4158e-5a8c-41c8-bcbe-396e7620900e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The \t 0 \t DET \t det \t ['boy', 'playing'] \t []\n",
            "boy \t 1 \t NOUN \t nsubj \t ['playing'] \t ['The']\n",
            "is \t 2 \t AUX \t aux \t ['playing'] \t []\n",
            "playing \t 3 \t VERB \t ROOT \t [] \t ['boy', 'is', 'in', '.']\n",
            "in \t 4 \t ADP \t prep \t ['playing'] \t ['garden']\n",
            "the \t 5 \t DET \t det \t ['garden', 'in', 'playing'] \t []\n",
            "garden \t 6 \t NOUN \t pobj \t ['in', 'playing'] \t ['the']\n",
            ". \t 7 \t PUNCT \t punct \t ['playing'] \t []\n",
            "\n",
            "Root token: playing\n",
            "\n",
            "Other verbs: []\n",
            "['boy is playing in the garden']\n"
          ]
        }
      ],
      "source": [
        "break_into_independent_clauses(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6-7TWNli7C2",
        "outputId": "2a42f2ca-2221-4275-9577-4fbede8cdb54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I \t 0 \t PRON \t nsubj \t ['going'] \t []\n",
            "was \t 1 \t AUX \t aux \t ['going'] \t []\n",
            "going \t 2 \t VERB \t ROOT \t [] \t ['I', 'was', 'for', 'today', 'and', 'on', '.']\n",
            "for \t 3 \t ADP \t prep \t ['going'] \t ['movie']\n",
            "a \t 4 \t DET \t det \t ['movie', 'for', 'going'] \t []\n",
            "movie \t 5 \t NOUN \t pobj \t ['for', 'going'] \t ['a']\n",
            "today \t 6 \t NOUN \t npadvmod \t ['going'] \t []\n",
            "and \t 7 \t CCONJ \t cc \t ['going'] \t []\n",
            "on \t 8 \t ADP \t conj \t ['going'] \t ['way']\n",
            "the \t 9 \t DET \t det \t ['way', 'on', 'going'] \t []\n",
            "way \t 10 \t NOUN \t pobj \t ['on', 'going'] \t ['the', 'met']\n",
            "I \t 11 \t PRON \t nsubj \t ['met', 'way', 'on', 'going'] \t []\n",
            "met \t 12 \t VERB \t relcl \t ['way', 'on', 'going'] \t ['I', 'Sudha']\n",
            "Sudha \t 13 \t PROPN \t dobj \t ['met', 'way', 'on', 'going'] \t []\n",
            ". \t 14 \t PUNCT \t punct \t ['going'] \t []\n",
            "\n",
            "Root token: going\n",
            "\n",
            "Other verbs: [met]\n",
            "['I was going for a movie today and on the way I met Sudha', 'I met']\n"
          ]
        }
      ],
      "source": [
        "break_into_independent_clauses(sentence)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66GJzFz9NGtu",
        "outputId": "f1e4ac71-dec0-45b4-aa4e-16c4a03d1c57"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I was going for a movie today\n",
            "on the way I met Sudha .\n"
          ]
        }
      ],
      "source": [
        "def break_into_independent_clauses(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Initialize a list to store independent clauses\n",
        "    independent_clauses = []\n",
        "\n",
        "    # Initialize a variable to keep track of the current clause\n",
        "    current_clause = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token.text.lower() == \"and\":\n",
        "            # When \"and\" is encountered, add the current clause to the list\n",
        "            if current_clause:\n",
        "                independent_clauses.append(\" \".join(current_clause))\n",
        "            current_clause = []  # Reset the current clause\n",
        "        else:\n",
        "            current_clause.append(token.text)\n",
        "\n",
        "    # Add the last clause (or the entire sentence if no \"and\" is found)\n",
        "    if current_clause:\n",
        "        independent_clauses.append(\" \".join(current_clause))\n",
        "\n",
        "    return independent_clauses\n",
        "\n",
        "# Input sentence\n",
        "sentence = \"I was going for a movie today and on the way I met Sudha.\"\n",
        "\n",
        "# Use the function to break the sentence into independent clauses\n",
        "independent_clauses = break_into_independent_clauses(sentence)\n",
        "\n",
        "# Print the independent clauses\n",
        "for clause in independent_clauses:\n",
        "    print(clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3n-UgnIlRlV"
      },
      "source": [
        "# Modified version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "kPnGeucwmBb8"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[1;32m/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb Cell 12\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mspacy\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39m# Load the English NLP model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ashwin/Acads/4-1/NLP_Project/CSify/Clause_generation.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m nlp \u001b[39m=\u001b[39m spacy\u001b[39m.\u001b[39;49mload(\u001b[39m\"\u001b[39;49m\u001b[39men_core_web_sm\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/spacy/__init__.py:51\u001b[0m, in \u001b[0;36mload\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mload\u001b[39m(\n\u001b[1;32m     28\u001b[0m     name: Union[\u001b[39mstr\u001b[39m, Path],\n\u001b[1;32m     29\u001b[0m     \u001b[39m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     config: Union[Dict[\u001b[39mstr\u001b[39m, Any], Config] \u001b[39m=\u001b[39m util\u001b[39m.\u001b[39mSimpleFrozenDict(),\n\u001b[1;32m     35\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Language:\n\u001b[1;32m     36\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Load a spaCy model from an installed package or a local path.\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \n\u001b[1;32m     38\u001b[0m \u001b[39m    name (str): Package name or model path.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m    RETURNS (Language): The loaded nlp object.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m util\u001b[39m.\u001b[39;49mload_model(\n\u001b[1;32m     52\u001b[0m         name,\n\u001b[1;32m     53\u001b[0m         vocab\u001b[39m=\u001b[39;49mvocab,\n\u001b[1;32m     54\u001b[0m         disable\u001b[39m=\u001b[39;49mdisable,\n\u001b[1;32m     55\u001b[0m         enable\u001b[39m=\u001b[39;49menable,\n\u001b[1;32m     56\u001b[0m         exclude\u001b[39m=\u001b[39;49mexclude,\n\u001b[1;32m     57\u001b[0m         config\u001b[39m=\u001b[39;49mconfig,\n\u001b[1;32m     58\u001b[0m     )\n",
            "File \u001b[0;32m~/miniconda3/envs/tensorflow/lib/python3.10/site-packages/spacy/util.py:472\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(name, vocab, disable, enable, exclude, config)\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m OLD_MODEL_SHORTCUTS:\n\u001b[1;32m    471\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE941\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname, full\u001b[39m=\u001b[39mOLD_MODEL_SHORTCUTS[name]))  \u001b[39m# type: ignore[index]\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mIOError\u001b[39;00m(Errors\u001b[39m.\u001b[39mE050\u001b[39m.\u001b[39mformat(name\u001b[39m=\u001b[39mname))\n",
            "\u001b[0;31mOSError\u001b[0m: [E050] Can't find model 'en_core_web_sm'. It doesn't seem to be a Python package or a valid path to a data directory."
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "# Load the English NLP model\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kVl1cGyblZJX"
      },
      "outputs": [],
      "source": [
        "def print_structure(sentence):\n",
        "  doc = nlp(sentence)\n",
        "\n",
        "  for token in doc:\n",
        "    ancestors = [t.text for t in token.ancestors]\n",
        "    children = [t.text for t in token.children]\n",
        "    print(token.text, \"\\t\", token.i, \"\\t\",\n",
        "    token.pos_, \"\\t\", token.dep_, \"\\t\\tAncestors: \",\n",
        "    ancestors, \"\\n\\t\\t\\t\\t\\tChildren: \", children)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ARUKZViqPJpo"
      },
      "outputs": [],
      "source": [
        "def break_into_independent_clauses(sentence):\n",
        "    doc = nlp(sentence)\n",
        "\n",
        "    # Initialize a list to store independent clauses\n",
        "    independent_clauses = []\n",
        "\n",
        "    # Initialize a variable to keep track of the current clause\n",
        "    current_clause = []\n",
        "\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"punct\" and token.text == \",\":\n",
        "            # When a comma is encountered, add the current clause to the list\n",
        "            if current_clause:\n",
        "                independent_clauses.append(\" \".join(current_clause))\n",
        "            current_clause = []  # Reset the current clause\n",
        "\n",
        "        elif token.dep_ == \"cc\": ##cc means conjunction\n",
        "        # elif token.text.lower() == \"and\":\n",
        "            if current_clause:\n",
        "                independent_clauses.append(\" \".join(current_clause))\n",
        "            independent_clauses.append(token.text)\n",
        "            current_clause = []  # Reset the current clause\n",
        "\n",
        "        elif token.dep_ == \"prep\" or token.pos_ == \"PART\" and token.dep_ == \"aux\" \\\n",
        "        or token.pos_ == \"PRON\" and token.dep_ == \"nsubj\":\n",
        "        #prep = preposition, pron = pronoun\n",
        "            if current_clause:\n",
        "                independent_clauses.append(\" \".join(current_clause))\n",
        "            current_clause = [token.text]  # Reset the current clause\n",
        "\n",
        "        else:\n",
        "            current_clause.append(token.text)\n",
        "\n",
        "    # Add the last clause (or the entire sentence if no comma is found)\n",
        "    if current_clause:\n",
        "        independent_clauses.append(\" \".join(current_clause))\n",
        "\n",
        "    return independent_clauses\n",
        "\n",
        "\n",
        "\n",
        "# Input sentence\n",
        "# sentence = \"I was going for a movie today, and on the way, I met Sudha.\"\n",
        "\n",
        "# Use the function to break the sentence into independent clauses\n",
        "# independent_clauses = break_into_independent_clauses(sentence)\n",
        "# print(independent_clauses)\n",
        "# Print the independent clauses\n",
        "# for clause in independent_clauses:\n",
        "#     print(clause)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ISJoQxW6VLju",
        "outputId": "fde6db37-027f-4619-9537-086148f166d9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['I was going', 'for a movie today', 'and', 'on the way', 'I met Sudha .']\n",
            "['The boy is playing', 'in the garden .']\n",
            "['Originating', 'from the Himalayas', 'the Ganga is a holy river .']\n",
            "['There are a few men standing', 'outside the palace .']\n",
            "['Needs someone', 'to explain lambda calculus', 'to him .']\n",
            "['I need', 'to take a class', 'or', 'find a new friend', 'who likes', 'to generate results']\n",
            "['She is tired waiting', 'at the airport']\n"
          ]
        }
      ],
      "source": [
        "sentences = [\"I was going for a movie today, and on the way, I met Sudha.\",\n",
        "             \"The boy is playing in the garden.\",\n",
        "             \"Originating from the Himalayas, the Ganga is a holy river.\",\n",
        "             \"There are a few men standing outside the palace.\",\n",
        "             \"Needs someone to explain lambda calculus to him.\",\n",
        "             \"I need to take a class or find a new friend who likes to generate results\",\n",
        "             \"She is tired waiting at the airport\"]\n",
        "for sentence in sentences:\n",
        "  independent_clauses = break_into_independent_clauses(sentence)\n",
        "  print(independent_clauses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2f05WFQlc7_",
        "outputId": "fb912755-abe2-4c7c-bd05-e42decaff7ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I \t 0 \t PRON \t nsubj \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "was \t 1 \t AUX \t aux \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "going \t 2 \t VERB \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['I', 'was', 'for', 'today', ',', 'and', 'met']\n",
            "for \t 3 \t ADP \t prep \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  ['movie']\n",
            "a \t 4 \t DET \t det \t\tAncestors:  ['movie', 'for', 'going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "movie \t 5 \t NOUN \t pobj \t\tAncestors:  ['for', 'going'] \n",
            "\t\t\t\t\tChildren:  ['a']\n",
            "today \t 6 \t NOUN \t npadvmod \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            ", \t 7 \t PUNCT \t punct \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "and \t 8 \t CCONJ \t cc \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "on \t 9 \t ADP \t prep \t\tAncestors:  ['met', 'going'] \n",
            "\t\t\t\t\tChildren:  ['way']\n",
            "the \t 10 \t DET \t det \t\tAncestors:  ['way', 'on', 'met', 'going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "way \t 11 \t NOUN \t pobj \t\tAncestors:  ['on', 'met', 'going'] \n",
            "\t\t\t\t\tChildren:  ['the']\n",
            ", \t 12 \t PUNCT \t punct \t\tAncestors:  ['met', 'going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "I \t 13 \t PRON \t nsubj \t\tAncestors:  ['met', 'going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "met \t 14 \t VERB \t conj \t\tAncestors:  ['going'] \n",
            "\t\t\t\t\tChildren:  ['on', ',', 'I', 'Sudha', '.']\n",
            "Sudha \t 15 \t PROPN \t dobj \t\tAncestors:  ['met', 'going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            ". \t 16 \t PUNCT \t punct \t\tAncestors:  ['met', 'going'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "....................................................................................................\n",
            "The \t 0 \t DET \t det \t\tAncestors:  ['boy', 'playing'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "boy \t 1 \t NOUN \t nsubj \t\tAncestors:  ['playing'] \n",
            "\t\t\t\t\tChildren:  ['The']\n",
            "is \t 2 \t AUX \t aux \t\tAncestors:  ['playing'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "playing \t 3 \t VERB \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['boy', 'is', 'in', '.']\n",
            "in \t 4 \t ADP \t prep \t\tAncestors:  ['playing'] \n",
            "\t\t\t\t\tChildren:  ['garden']\n",
            "the \t 5 \t DET \t det \t\tAncestors:  ['garden', 'in', 'playing'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "garden \t 6 \t NOUN \t pobj \t\tAncestors:  ['in', 'playing'] \n",
            "\t\t\t\t\tChildren:  ['the']\n",
            ". \t 7 \t PUNCT \t punct \t\tAncestors:  ['playing'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "....................................................................................................\n",
            "Originating \t 0 \t VERB \t advcl \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  ['from']\n",
            "from \t 1 \t ADP \t prep \t\tAncestors:  ['Originating', 'is'] \n",
            "\t\t\t\t\tChildren:  ['Himalayas']\n",
            "the \t 2 \t DET \t det \t\tAncestors:  ['Himalayas', 'from', 'Originating', 'is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "Himalayas \t 3 \t PROPN \t pobj \t\tAncestors:  ['from', 'Originating', 'is'] \n",
            "\t\t\t\t\tChildren:  ['the']\n",
            ", \t 4 \t PUNCT \t punct \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "the \t 5 \t DET \t det \t\tAncestors:  ['Ganga', 'is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "Ganga \t 6 \t PROPN \t nsubj \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  ['the']\n",
            "is \t 7 \t AUX \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['Originating', ',', 'Ganga', 'river', '.']\n",
            "a \t 8 \t DET \t det \t\tAncestors:  ['river', 'is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "holy \t 9 \t ADJ \t amod \t\tAncestors:  ['river', 'is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "river \t 10 \t NOUN \t attr \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  ['a', 'holy']\n",
            ". \t 11 \t PUNCT \t punct \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "....................................................................................................\n",
            "There \t 0 \t PRON \t expl \t\tAncestors:  ['are'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "are \t 1 \t VERB \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['There', 'men', '.']\n",
            "a \t 2 \t DET \t quantmod \t\tAncestors:  ['few', 'men', 'are'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "few \t 3 \t ADJ \t nummod \t\tAncestors:  ['men', 'are'] \n",
            "\t\t\t\t\tChildren:  ['a']\n",
            "men \t 4 \t NOUN \t attr \t\tAncestors:  ['are'] \n",
            "\t\t\t\t\tChildren:  ['few', 'standing']\n",
            "standing \t 5 \t VERB \t acl \t\tAncestors:  ['men', 'are'] \n",
            "\t\t\t\t\tChildren:  ['outside']\n",
            "outside \t 6 \t ADP \t prep \t\tAncestors:  ['standing', 'men', 'are'] \n",
            "\t\t\t\t\tChildren:  ['palace']\n",
            "the \t 7 \t DET \t det \t\tAncestors:  ['palace', 'outside', 'standing', 'men', 'are'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "palace \t 8 \t NOUN \t pobj \t\tAncestors:  ['outside', 'standing', 'men', 'are'] \n",
            "\t\t\t\t\tChildren:  ['the']\n",
            ". \t 9 \t PUNCT \t punct \t\tAncestors:  ['are'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "....................................................................................................\n",
            "Needs \t 0 \t VERB \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['someone', '.']\n",
            "someone \t 1 \t PRON \t dobj \t\tAncestors:  ['Needs'] \n",
            "\t\t\t\t\tChildren:  ['explain']\n",
            "to \t 2 \t PART \t aux \t\tAncestors:  ['explain', 'someone', 'Needs'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "explain \t 3 \t VERB \t relcl \t\tAncestors:  ['someone', 'Needs'] \n",
            "\t\t\t\t\tChildren:  ['to', 'calculus', 'to']\n",
            "lambda \t 4 \t ADJ \t compound \t\tAncestors:  ['calculus', 'explain', 'someone', 'Needs'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "calculus \t 5 \t NOUN \t dobj \t\tAncestors:  ['explain', 'someone', 'Needs'] \n",
            "\t\t\t\t\tChildren:  ['lambda']\n",
            "to \t 6 \t ADP \t prep \t\tAncestors:  ['explain', 'someone', 'Needs'] \n",
            "\t\t\t\t\tChildren:  ['him']\n",
            "him \t 7 \t PRON \t pobj \t\tAncestors:  ['to', 'explain', 'someone', 'Needs'] \n",
            "\t\t\t\t\tChildren:  []\n",
            ". \t 8 \t PUNCT \t punct \t\tAncestors:  ['Needs'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "....................................................................................................\n",
            "I \t 0 \t PRON \t nsubj \t\tAncestors:  ['need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "need \t 1 \t VERB \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['I', 'take']\n",
            "to \t 2 \t PART \t aux \t\tAncestors:  ['take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "take \t 3 \t VERB \t xcomp \t\tAncestors:  ['need'] \n",
            "\t\t\t\t\tChildren:  ['to', 'class', 'or', 'find']\n",
            "a \t 4 \t DET \t det \t\tAncestors:  ['class', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "class \t 5 \t NOUN \t dobj \t\tAncestors:  ['take', 'need'] \n",
            "\t\t\t\t\tChildren:  ['a']\n",
            "or \t 6 \t CCONJ \t cc \t\tAncestors:  ['take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "find \t 7 \t VERB \t conj \t\tAncestors:  ['take', 'need'] \n",
            "\t\t\t\t\tChildren:  ['friend']\n",
            "a \t 8 \t DET \t det \t\tAncestors:  ['friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "new \t 9 \t ADJ \t amod \t\tAncestors:  ['friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "friend \t 10 \t NOUN \t dobj \t\tAncestors:  ['find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  ['a', 'new', 'likes']\n",
            "who \t 11 \t PRON \t nsubj \t\tAncestors:  ['likes', 'friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "likes \t 12 \t VERB \t relcl \t\tAncestors:  ['friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  ['who', 'generate']\n",
            "to \t 13 \t PART \t aux \t\tAncestors:  ['generate', 'likes', 'friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "generate \t 14 \t VERB \t xcomp \t\tAncestors:  ['likes', 'friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  ['to', 'results']\n",
            "results \t 15 \t NOUN \t dobj \t\tAncestors:  ['generate', 'likes', 'friend', 'find', 'take', 'need'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "....................................................................................................\n",
            "She \t 0 \t PRON \t nsubj \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "is \t 1 \t AUX \t ROOT \t\tAncestors:  [] \n",
            "\t\t\t\t\tChildren:  ['She', 'tired', 'waiting']\n",
            "tired \t 2 \t ADJ \t acomp \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "waiting \t 3 \t VERB \t xcomp \t\tAncestors:  ['is'] \n",
            "\t\t\t\t\tChildren:  ['at']\n",
            "at \t 4 \t ADP \t prep \t\tAncestors:  ['waiting', 'is'] \n",
            "\t\t\t\t\tChildren:  ['airport']\n",
            "the \t 5 \t DET \t det \t\tAncestors:  ['airport', 'at', 'waiting', 'is'] \n",
            "\t\t\t\t\tChildren:  []\n",
            "airport \t 6 \t NOUN \t pobj \t\tAncestors:  ['at', 'waiting', 'is'] \n",
            "\t\t\t\t\tChildren:  ['the']\n",
            "....................................................................................................\n"
          ]
        }
      ],
      "source": [
        "for sentence in sentences:\n",
        "  print_structure(sentence)\n",
        "  print('.' * 100)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
